{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4729.92s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "4735.95s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "4741.76s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "4747.55s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "# Installing required dependencies \n",
    "!pip install -Uqqq pip --progress-bar off\n",
    "!pip install -qqq groq==0.13.0 --progress-bar off\n",
    "!pip install -qqq python-dotenv==1.0.1 --progress-bar off\n",
    "!pip install -qqq fpdf pandas matplotlib seaborn requests --progress-bar off\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing  Libraries\n",
    " \n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from groq import Groq\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initializing Groq API\n",
    " \n",
    "Groq_API_key = \"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\"  \n",
    "client = Groq(api_key=Groq_API_key)\n",
    "\n",
    "MISSING_VALUE_INDICATORS = [\"?\", \"NA\", \"N/A\", \"NaN\", \"NULL\", \"\", \"Unknown\", \"missing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Loading Dataset with Missing Value Detection\n",
    " \n",
    "dataset_path = \"Automobile_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset Loaded Successfully!\n",
      "\n",
      "Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205 entries, 0 to 204\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   symboling          205 non-null    int64  \n",
      " 1   normalized-losses  164 non-null    float64\n",
      " 2   make               205 non-null    object \n",
      " 3   fuel-type          205 non-null    object \n",
      " 4   aspiration         205 non-null    object \n",
      " 5   num-of-doors       203 non-null    object \n",
      " 6   body-style         205 non-null    object \n",
      " 7   drive-wheels       205 non-null    object \n",
      " 8   engine-location    205 non-null    object \n",
      " 9   wheel-base         205 non-null    float64\n",
      " 10  length             205 non-null    float64\n",
      " 11  width              205 non-null    float64\n",
      " 12  height             205 non-null    float64\n",
      " 13  curb-weight        205 non-null    int64  \n",
      " 14  engine-type        205 non-null    object \n",
      " 15  num-of-cylinders   205 non-null    object \n",
      " 16  engine-size        205 non-null    int64  \n",
      " 17  fuel-system        205 non-null    object \n",
      " 18  bore               201 non-null    float64\n",
      " 19  stroke             201 non-null    float64\n",
      " 20  compression-ratio  205 non-null    float64\n",
      " 21  horsepower         203 non-null    float64\n",
      " 22  peak-rpm           203 non-null    float64\n",
      " 23  city-mpg           205 non-null    int64  \n",
      " 24  highway-mpg        205 non-null    int64  \n",
      " 25  price              201 non-null    float64\n",
      "dtypes: float64(11), int64(5), object(10)\n",
      "memory usage: 41.8+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      " symboling             0\n",
      "normalized-losses    41\n",
      "make                  0\n",
      "fuel-type             0\n",
      "aspiration            0\n",
      "num-of-doors          2\n",
      "body-style            0\n",
      "drive-wheels          0\n",
      "engine-location       0\n",
      "wheel-base            0\n",
      "length                0\n",
      "width                 0\n",
      "height                0\n",
      "curb-weight           0\n",
      "engine-type           0\n",
      "num-of-cylinders      0\n",
      "engine-size           0\n",
      "fuel-system           0\n",
      "bore                  4\n",
      "stroke                4\n",
      "compression-ratio     0\n",
      "horsepower            2\n",
      "peak-rpm              2\n",
      "city-mpg              0\n",
      "highway-mpg           0\n",
      "price                 4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    " \n",
    "df = pd.read_csv(\"Automobile_data.csv\", na_values=MISSING_VALUE_INDICATORS)\n",
    "\n",
    "print(\" Dataset Loaded Successfully!\")\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " AI-Powered Data Science Recommendations:\n",
      " Based on the dataset summary, I provide the following recommendations for the data science workflow:\n",
      "\n",
      "**1. Handling Missing Values**\n",
      "\n",
      "* For columns with a small number of missing values (less than 5%), I recommend filling them with the median or mean for numerical columns (e.g., `bore`, `stroke`, `horsepower`, `peak-rpm`, and `price`) and the mode for categorical columns (e.g., `num-of-doors`).\n",
      "* For columns with a larger number of missing values (e.g., `normalized-losses`), I recommend creating a 'Missing' category, as this might be a relevant feature in the analysis.\n",
      "* Dropping rows or columns with missing values might not be the best approach, as it could lead to loss of valuable information and biased results.\n",
      "\n",
      "**2. Recommended Visualizations**\n",
      "\n",
      "* Histograms for numerical columns (e.g., `engine-size`, `horsepower`, `city-mpg`, `highway-mpg`, and `price`) to understand the distribution of values.\n",
      "* Scatter plots for numerical columns (e.g., `wheel-base` vs. `length`, `width` vs. `height`, and `horsepower` vs. `peak-rpm`) to identify correlations and relationships between variables.\n",
      "* Box plots for categorical columns (e.g., `make`, `fuel-type`, and `body-style`) to compare distributions across categories.\n",
      "* Correlation heatmaps for all numerical columns to identify strong correlations and potentially reduce dimensionality.\n",
      "\n",
      "**3. Machine Learning Model Recommendations**\n",
      "\n",
      "* Based on the dataset, I recommend a regression model, as the target variable `price` is continuous.\n",
      "* Suitable models include:\n",
      "\t+ Linear Regression: a simple and interpretable model for predicting `price` based on other numerical features.\n",
      "\t+ Decision Trees: a robust model that can handle non-linear relationships and interactions between features.\n",
      "\t+ Random Forest: an ensemble method that can improve the accuracy and robustness of Decision Trees.\n",
      "\t+ Gradient Boosting: another ensemble method that can handle complex relationships and interactions between features.\n",
      "\n",
      "**4. Model Evaluation Techniques**\n",
      "\n",
      "* For regression models, I recommend evaluating models using:\n",
      "\t+ Root Mean Squared Error (RMSE): measures the average distance between predicted and actual values.\n",
      "\t+ Mean Absolute Error (MAE): measures the average absolute difference between predicted and actual values.\n",
      "\t+ RÂ²-score (Coefficient of Determination): measures the proportion of variance in the target variable explained by the model.\n",
      "* These metrics provide a comprehensive understanding of the model's performance, including accuracy, bias, and variance.\n",
      "\n",
      "By following these recommendations, you can develop a robust data science workflow that effectively handles missing values, explores the dataset through informative visualizations, and selects suitable machine learning models with appropriate evaluation metrics.\n"
     ]
    }
   ],
   "source": [
    "#  Prompting\n",
    "def generate_ai_prompt(df):\n",
    "    missing_values = df.isnull().sum().to_string()\n",
    "    column_types = df.dtypes.to_string()\n",
    "\n",
    "    prompt = f\"\"\" \n",
    "    Analyze the dataset and provide **recommendations** for the data science workflow.\n",
    "\n",
    "    **Dataset Summary**\n",
    "    - Column Data Types: {column_types}\n",
    "    - Missing Values Summary: {missing_values}\n",
    "\n",
    "    1 **Handling Missing Values**\n",
    "       - Should we drop rows/columns?\n",
    "       - Should we fill missing values with mean, median, or mode?\n",
    "       - Should we create a 'Missing' category?\n",
    "\n",
    "    2 **Recommended Visualizations** (DO NOT GENERATE, JUST SUGGEST)\n",
    "       - Suggest histograms, scatter plots, box plots, or correlation heatmaps based on dataset type.\n",
    "       - Explain why each visualization is relevant.\n",
    "\n",
    "    3 **Machine Learning Model Recommendations**\n",
    "       - Is this dataset suitable for classification, regression, or clustering?\n",
    "       - Suggest appropriate ML models (e.g., Logistic Regression, Decision Trees, Random Forest, K-Means, etc.).\n",
    "       - Justify why each model is suitable.\n",
    "\n",
    "    4 **Model Evaluation Techniques**\n",
    "       - Identify which **evaluation metrics** are best suited for this dataset.\n",
    "       - If the dataset is **classification**, recommend: Accuracy, Precision, Recall, F1-score, AUC-ROC, and explain why.\n",
    "       - If the dataset is **regression**, recommend: RMSE, MAE, RÂ²-score, and explain why.\n",
    "       - If the dataset is **clustering**, recommend: Silhouette Score, Davies-Bouldin Index, Adjusted Rand Index, and explain why.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Call LLaMA 3 API \n",
    "ai_prompt = generate_ai_prompt(df)\n",
    "\n",
    "try:\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": ai_prompt}],\n",
    "        model=\"llama3-70b-8192\"\n",
    "    )\n",
    "\n",
    "    # Ensuring response is valid\n",
    "    if not chat_completion.choices or not chat_completion.choices[0].message.content:\n",
    "        print(\"\\n ERROR: AI Response is empty!\")\n",
    "        ai_response = \"No AI response received. Please check your API key or try again.\"\n",
    "    else:\n",
    "        ai_response = chat_completion.choices[0].message.content\n",
    "        print(\"\\n AI-Powered Data Science Recommendations:\\n\", ai_response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n ERROR: API call failed!\", str(e))\n",
    "    ai_response = \"No AI response received due to an error.\"\n",
    "\n",
    "# Ensure response is saved for later steps\n",
    "with open(\"ai_response.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(ai_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " AI-Generated Report saved as: Report.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Ensuring model response is properly loaded from file\n",
    "if os.path.exists(\"ai_response.txt\"):\n",
    "    with open(\"ai_response.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        ai_response = f.read()\n",
    "else:\n",
    "    ai_response = \" No AI response found. Please check Step 4.\"\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font(\"Arial\", \"B\", 16)\n",
    "        self.cell(200, 10, \"Data Science Recommendations\", ln=True, align=\"C\")\n",
    "        self.ln(10)\n",
    "        self.set_font(\"Arial\", \"I\", 12)\n",
    "        self.cell(200, 10, \"A comprehensive analysis and recommendations report\", ln=True, align=\"C\")\n",
    "        self.ln(20)\n",
    "\n",
    "    def footer(self):\n",
    "        self.set_y(-15)\n",
    "        self.set_font(\"Arial\", \"I\", 10)\n",
    "        self.cell(0, 10, f\"Page {self.page_no()}\", align=\"C\")\n",
    "\n",
    "def generate_pdf_report(text, filename):\n",
    "    pdf = PDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    " \n",
    "    \n",
    "    pdf.ln(10)   \n",
    "\n",
    "    # Inserting AI Response\n",
    "    pdf.set_font(\"Arial\", \"B\", 14)\n",
    "    pdf.cell(0, 10, \"Your Report\", ln=True)\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.multi_cell(0, 10, text)\n",
    "\n",
    "    # Save the PDF\n",
    "    pdf.output(filename)\n",
    "    print(f\"\\n AI-Generated Report saved as: {filename}\")\n",
    "\n",
    "# Generate the PDF Report\n",
    "generate_pdf_report(ai_response, \"Report.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
