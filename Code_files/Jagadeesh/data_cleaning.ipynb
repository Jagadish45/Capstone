{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Data Cleaning Report\n",
      "\n",
      "## 1. Introduction\n",
      "This report provides a comprehensive analysis of potential data quality issues present in the dataset. The dataset contains information about various car attributes including symbolic representation, normalized losses, make, fuel type, aspiration, number of doors, body style, drive wheels, engine location, wheel base, length, width, height, curb weight, engine type, number of cylinders, engine size, fuel system, bore, stroke, compression ratio, horsepower, peak RPM, city MPG, highway MPG, and price.\n",
      "\n",
      "## 2. Data Quality Issues\n",
      "\n",
      "### 2.1 Missing Values\n",
      "- **Description:** The dataset contains rows where the `normalized-losses` column has missing values indicated by `?`.\n",
      "- **Count:** There are 5 rows with missing values in the `normalized-losses` column.\n",
      "- **Recommendations:** There are several ways to handle missing values in the `normalized-losses` column:\n",
      "  - **Imputation:** Replace missing values with an appropriate statistic (mean, median, or mode) of the `normalized-losses` column.\n",
      "  - **Removal:** If the proportion of missing values is small and they are randomly distributed, consider removing these rows. However, given the context, removing 5 rows (approximately 14%) might not be advisable.\n",
      "  - **Flagging:** Add a new column indicating the presence of missing values. This can be useful for future analysis to see if there's any pattern or correlation between the missing values and other variables.\n",
      "  - **Model-based Imputation:** Use advanced techniques like k-Nearest Neighbors (k-NN) or regression imputation to fill in the missing values based on other features.\n",
      "\n",
      "### 2.2 Duplicate Rows\n",
      "- **Description:** Identify exact duplicates in the dataset.\n",
      "- **Count:** There are 2 exact duplicate rows.\n",
      "  - Example of duplicate rows:\n",
      "    ```\n",
      "    1,158,audi,gas,std,four,sedan,fwd,front,105.8,192.7,71.4,55.7,2844,ohc,five,136,mpfi,3.19,3.4,8.5,110,5500,19,25,17710\n",
      "    1,158,audi,gas,std,four,sedan,fwd,front,105.8,192.7,71.4,55.7,2844,ohc,five,136,mpfi,3.19,3.4,8.5,110,5500,19,25,17710\n",
      "    ```\n",
      "- **Recommendations:** Remove the duplicate rows as they do not provide additional information and could skew analysis.\n",
      "\n",
      "### 2.3 Inconsistent Data Formats\n",
      "- **Description:** There are no explicit inconsistencies in the data formats, but it’s important to ensure that all numerical and categorical data are in a consistent format.\n",
      "- **Count:** N/A\n",
      "- **Recommendations:**\n",
      "  - Verify that all numerical columns are stored as numerical data types.\n",
      "  - Ensure categorical columns have consistent encoding, such as uniform casing (e.g., all lowercase or uppercase).\n",
      "  - Check for any leading or trailing spaces in categorical variables and remove them.\n",
      "\n",
      "### 2.4 Outliers and Irregularities\n",
      "- **Description:** Analyze numerical columns to detect and quantify outliers or anomalous values.\n",
      "- **Count:** Outliers in `price` and `horsepower` columns need to be identified.\n",
      "- **Recommendations:**\n",
      "  - **Price Column:**\n",
      "    - Identify and analyze outliers in the `price` column using statistical methods such as the Interquartile Range (IQR) or Z-score.\n",
      "    - If outliers are found, consider:\n",
      "      - Removing outliers if they are deemed to be errors or anomalies.\n",
      "      - Flagging outliers for further review.\n",
      "      - Using robust statistical methods that are less sensitive to outliers.\n",
      "  - **Horsepower Column:**\n",
      "    - Similarly, identify and analyze outliers in the `horsepower` column.\n",
      "    - Use the same approach as for the `price` column to handle these outliers.\n",
      "\n",
      "### 2.5 Data Distribution\n",
      "- **Description:** Ensure data is normally distributed where applicable and handle any skewness.\n",
      "- **Count:** N/A\n",
      "- **Recommendations:**\n",
      "  - Check the distribution of numerical columns.\n",
      "  - Use transformations like log or square root to normalize the skewed data.\n",
      "\n",
      "## 3. Final Recommendations\n",
      "\n",
      "1. **Handling Missing Values:**\n",
      "   - **Impute Missing Values:** Use mean or median imputation for the `normalized-losses` column to maintain data integrity.\n",
      "   - **Implement Flagging:** Add a new column to flag rows with missing values for transparency and future analysis.\n",
      "\n",
      "2. **Removing Duplicates:**\n",
      "   - **Remove Duplicate Rows:** Identify and remove the exact duplicate rows to ensure data uniqueness.\n",
      "\n",
      "3. **Consistent Data Formats:**\n",
      "   - **Uniform Formatting:** Ensure all numerical columns are numerical data types and all categorical columns are consistently encoded.\n",
      "\n",
      "4. **Handling Outliers:**\n",
      "   - **Identify and Handle Outliers:** Use statistical methods to identify and handle outliers in the `price` and `horsepower` columns. Consider removing or flagging outliers based on the context and impact on analysis.\n",
      "\n",
      "5. **Data Distribution:**\n",
      "   - **Normalize Skewed Data:** Apply transformations to normalize skewed numerical columns.\n",
      "\n",
      "By following these recommendations, the dataset will be cleaned and prepared for further analysis or modeling tasks.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "api_key = \"Use_your_own_damn_key\"\n",
    "model = \"mistral-small-latest\"\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an experienced data scientist specializing in data cleaning for large datasets. Below is a sample of a dataset I'm working with:\n",
    "\n",
    "symboling,normalized-losses,make,fuel-type,aspiration,num-of-doors,body-style,drive-wheels,engine-location,wheel-base,length,width,height,curb-weight,engine-type,num-of-cylinders,engine-size,fuel-system,bore,stroke,compression-ratio,horsepower,peak-rpm,city-mpg,highway-mpg,price\n",
    "3,?,alfa-romero,gas,std,two,convertible,rwd,front,88.6,168.8,64.1,48.8,2548,dohc,four,130,mpfi,3.47,2.68,9,111,5000,21,27,13495\n",
    "3,?,alfa-romero,gas,std,two,convertible,rwd,front,88.6,168.8,64.1,48.8,2548,dohc,four,130,mpfi,3.47,2.68,9,111,5000,21,27,16500\n",
    "1,?,alfa-romero,gas,std,two,hatchback,rwd,front,94.5,171.2,65.5,52.4,2823,ohcv,six,152,mpfi,2.68,3.47,9,154,5000,19,26,16500\n",
    "2,164,audi,gas,std,four,sedan,fwd,front,99.8,176.6,66.2,54.3,2337,ohc,four,109,mpfi,3.19,3.4,10,102,5500,24,30,13950\n",
    "2,164,audi,gas,std,four,sedan,4wd,front,99.4,176.6,66.4,54.3,2824,ohc,five,136,mpfi,3.19,3.4,8,115,5500,18,22,17450\n",
    "2,?,audi,gas,std,two,sedan,fwd,front,99.8,177.3,66.3,53.1,2507,ohc,five,136,mpfi,3.19,3.4,8.5,110,5500,19,25,15250\n",
    "1,158,audi,gas,std,four,sedan,fwd,front,105.8,192.7,71.4,55.7,2844,ohc,five,136,mpfi,3.19,3.4,8.5,110,5500,19,25,17710\n",
    "1,?,audi,gas,std,four,wagon,fwd,front,105.8,192.7,71.4,55.7,2954,ohc,five,136,mpfi,3.19,3.4,8.5,110,5500,19,25,18920\n",
    "1,158,audi,gas,turbo,four,sedan,fwd,front,105.8,192.7,71.4,55.9,3086,ohc,five,131,mpfi,3.13,3.4,8.3,140,5500,17,20,23875\n",
    "\n",
    "The dataset may have the following issues:\n",
    "- **Empty or Missing Values:** Some rows have missing values (denoted by “?”). Please identify and count these rows.\n",
    "- **Duplicate Rows:** Identify if any rows are exact duplicates.\n",
    "- **Inconsistent Data Formats:** Although there are no date columns, check for inconsistent formats in numerical or categorical data.\n",
    "- **Outliers and Other Irregularities:** Analyze numerical columns (e.g., price, horsepower) to detect and quantify outliers or anomalous values. Provide specific counts or ranges.\n",
    "\n",
    "Your task is to:\n",
    "1. Analyze the dataset and list every potential data quality issue in detail.\n",
    "2. For each issue, provide:\n",
    "   - A clear description.\n",
    "   - The count or proportion of affected rows.\n",
    "   - Detailed, specific recommendations on the best way to address the issue (for example, whether to remove, impute, or flag the problematic data).\n",
    "3. Do not include any code; focus solely on analysis and recommendations.\n",
    "4. Present your response in clear markdown with headings, bullet points, and structured sections.\n",
    "5. Additionally, explain your reasoning step by step before summarizing your final recommendations.\n",
    "\n",
    "Please produce a comprehensive data cleaning report as a data scientist would.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "chat_response = client.chat.complete(\n",
    "    model= model,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },],\n",
    "    temperature = 0.7)\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
