{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned-Up Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Install necessary packages (uncomment if needed in a notebook)\n",
    "# %pip install -qqq groq==0.13.0\n",
    "# %pip install fpdf -q\n",
    "\n",
    "import os\n",
    "import httpx\n",
    "import pandas as pd\n",
    "from groq import Groq\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from fpdf import FPDF\n",
    "\n",
    "MISSING_VALUE_INDICATORS = [\n",
    "    \"?\", \"NA\", \"N/A\", \"NaN\", \"NULL\", \"\", \"Unknown\", \"unknown\", \"missing\", \"Missing\"\n",
    "]\n",
    "LLM_MODEL_NAME = \"llama3-70b-8192\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Groq client (disable SSL verify only for demonstration; not recommended in production)\n",
    "groq_client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    "    http_client=httpx.Client(verify=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global system prompt for consistent structure\n",
    "SYSTEM_PROMPT = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "    You are an AI assistant helping generate structured and concise data science sections.\n",
    "    Adhere to these rules:\n",
    "    1. Use headings: # for main sections and ## or ### for subsections.\n",
    "    2. Keep each section concise and to the point.\n",
    "    3. Avoid repeating dataset overviews or the word 'report' in each section.\n",
    "    4. Do not add lines of ========= or unnecessary lines before or after headings.\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_file(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a dataset from a file into a DataFrame. Accepts CSV, Excel, or JSON.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path, na_values=MISSING_VALUE_INDICATORS)\n",
    "        elif file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path, na_values=MISSING_VALUE_INDICATORS)\n",
    "        elif file_path.endswith('.json'):\n",
    "            df = pd.read_json(file_path)\n",
    "            df.replace(MISSING_VALUE_INDICATORS, pd.NA, inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Use CSV, Excel, or JSON.\")\n",
    "\n",
    "        if df.empty:\n",
    "            raise ValueError(\"The dataset is empty.\")\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt_with_dataset(df: pd.DataFrame, goal: str) -> str:\n",
    "    \"\"\"\n",
    "    Builds a user prompt with minimal overview plus a final goal or request.\n",
    "    \"\"\"\n",
    "    # Show a short snippet, not an entire repeated \"overview\" for each section\n",
    "    # But keep enough context in case it's needed:\n",
    "    dataset_head = df.head().to_markdown()  # Using markdown to show columns more clearly\n",
    "    dataset_describe = df.describe().to_markdown()\n",
    "    missing_vals = df.isnull().sum()\n",
    "    missing_values_summary = missing_vals[missing_vals != 0].to_string()\n",
    "    column_types = df.dtypes.to_string()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Dataset Head (first 5 rows):\n",
    "    {dataset_head}\n",
    "\n",
    "    Dataset Statistics (describe):\n",
    "    {dataset_describe}\n",
    "\n",
    "    Missing Values:\n",
    "    {missing_values_summary if missing_values_summary.strip() else 'No missing values'}\n",
    "\n",
    "    Column Data Types:\n",
    "    {column_types}\n",
    "\n",
    "    Task:\n",
    "    {goal}\n",
    "    \"\"\"\n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Generates the Data Preprocessing & Cleaning section.\n",
    "    \"\"\"\n",
    "    # Summaries\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_values_pct = (missing_values / df.shape[0] * 100).round(2).astype(str) + \"%\"\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    unique_values = df.nunique()\n",
    "\n",
    "    # Build the user goal (with heading)\n",
    "    user_goal = f\"\"\"\n",
    "    # **Data Preprocessing & Cleaning**\n",
    "    1. Show the first five rows of the dataset with all columns in a table-like format (no extra introduction text).\n",
    "    2. Summarize missing values and duplicates (Missing values: {missing_values_pct.to_string()}, Duplicates: {duplicate_count}).\n",
    "    3. Summarize unique values per column: {unique_values.to_string()}.\n",
    "    4. Explain any cleaning steps that might be needed and how they affect the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = generate_user_prompt_with_dataset(df, user_goal)\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[SYSTEM_PROMPT, \n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        model=LLM_MODEL_NAME\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_statistical_summary(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Generates the Statistical Analysis section.\n",
    "    \"\"\"\n",
    "    user_goal = \"\"\"\n",
    "    # **Statistical Analysis**\n",
    "    1. Show the numeric summary table (df.describe()) in a markdown/table format.\n",
    "    2. Interpret the mean, std, min, max, etc.\n",
    "    3. Suggest next steps based on distributions.\n",
    "    \"\"\"\n",
    "    user_prompt = generate_user_prompt_with_dataset(df, user_goal)\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[SYSTEM_PROMPT, \n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        model=LLM_MODEL_NAME\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Generates the Exploratory Data Analysis section.\n",
    "    \"\"\"\n",
    "    user_goal = \"# **Exploratory Data Analysis**\\nSuggest EDA techniques (visualization ideas, correlation checks, outlier detection).\"\n",
    "    user_prompt = generate_user_prompt_with_dataset(df, user_goal)\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[SYSTEM_PROMPT, \n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        model=LLM_MODEL_NAME\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_suggestions(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Generates ML Algorithm Selection suggestions.\n",
    "    \"\"\"\n",
    "    user_goal = \"# **Machine Learning Suggestions**\\nDiscuss supervised and unsupervised methods relevant to this dataset.\"\n",
    "    user_prompt = generate_user_prompt_with_dataset(df, user_goal)\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[SYSTEM_PROMPT, \n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        model=LLM_MODEL_NAME\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_egr(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Generates Feature Engineering suggestions.\n",
    "    \"\"\"\n",
    "    user_goal = \"# **Feature Engineering**\\nDiscuss feature creation, transformation, and selection approaches.\"\n",
    "    user_prompt = generate_user_prompt_with_dataset(df, user_goal)\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[SYSTEM_PROMPT, \n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        model=LLM_MODEL_NAME\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deployment(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Generates Model Deployment & Data Drift suggestions.\n",
    "    \"\"\"\n",
    "    user_goal = \"# **Model Deployment & Data Drift**\\nPropose strategies for deploying models and handling data drift.\"\n",
    "    user_prompt = generate_user_prompt_with_dataset(df, user_goal)\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[SYSTEM_PROMPT, \n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        model=LLM_MODEL_NAME\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conclusion(df: pd.DataFrame, combined: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates the Conclusion section.\n",
    "    \"\"\"\n",
    "    user_goal = f\"\"\"\n",
    "    # **Conclusion**\n",
    "    Provide a concluding section referring to the overall insights. Keep it succinct.\n",
    "    \"\"\"\n",
    "    user_prompt = generate_user_prompt_with_dataset(df, user_goal + f\"\\nSections combined:\\n{combined}\")\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[SYSTEM_PROMPT, \n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        model=LLM_MODEL_NAME\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(df: pd.DataFrame, file_name: str = \"automated_report.md\") -> str:\n",
    "    \"\"\"\n",
    "    Generates a multi-section AI-written document for a dataset and saves to a file.\n",
    "    \"\"\"\n",
    "    steps = [\n",
    "        preprocess_data,\n",
    "        create_statistical_summary,\n",
    "        eda,\n",
    "        ml_suggestions,\n",
    "        feature_egr,\n",
    "        model_deployment\n",
    "    ]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(lambda func: func(df), steps))\n",
    "\n",
    "    combined_report = \"\\n\\n\".join(results)\n",
    "    final_section = conclusion(df, combined_report)\n",
    "    full_report = combined_report + \"\\n\\n\" + final_section\n",
    "\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_report)\n",
    "\n",
    "    return os.path.abspath(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generated at: /Users/ghizlanerehioui/Downloads/Capstone/Code_files/Ghizlane/Automobile_2_Clean_Up.md\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../../Data Files/Automobile/Automobile_data.csv\"\n",
    "df = load_dataset_from_file(file_path)\n",
    "if df is not None:\n",
    "    report_path = generate_report(df, f\"{file_path.split('/')[3]}_2_Clean_Up.md\")\n",
    "    print(f\"Report generated at: {report_path}\")\n",
    "    #generate_pdf_report_from_markdown(report_path, report_path.split('/')[-1][:-2]+\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generated at: /Users/ghizlanerehioui/Downloads/Capstone/Code_files/Ghizlane/Customer Experience_2_Clean_Up.md\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../../Data Files/Customer Experience/Car_Reviews_Database.csv\"\n",
    "df = load_dataset_from_file(file_path)\n",
    "if df is not None:\n",
    "    report_path = generate_report(df, f\"{file_path.split('/')[3]}_2_Clean_Up.md\")\n",
    "    print(f\"Report generated at: {report_path}\")\n",
    "    #generate_pdf_report_from_markdown(report_path, report_path.split('/')[-1][:-2]+\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change md to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will generate a PDF report from the markdown file\n",
    "def generate_pdf_report_from_markdown(md_file: str, pdf_file: str, ttf_font_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Reads a Markdown file and generates a PDF using FPDF with an embedded TrueType font.\n",
    "    This allows printing Unicode characters like the bullet (•).\n",
    "\n",
    "    :param md_file: Path to the input Markdown file.\n",
    "    :param pdf_file: Path where the output PDF will be saved.\n",
    "    :param ttf_font_path: Path to a TrueType font file with broad Unicode support.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new PDF\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "\n",
    "    # Register/Embed the TTF font. \n",
    "    #    - \"DejaVu\" is just a name; you can pick any label you want.\n",
    "    #    - Make sure ttf_font_path is the full path to your TTF file, e.g. \"fonts/DejaVuSansCondensed.ttf\"\n",
    "    pdf.add_font(\"DejaVu\", fname=ttf_font_path, uni=True)\n",
    "\n",
    "    # Helper to write lines with the embedded font\n",
    "    def write_line(text: str, style: str = \"\", size: int = 12):\n",
    "        # Set the newly added font\n",
    "        pdf.set_font(\"DejaVu\", style=style, size=size)\n",
    "        # multi_cell automatically wraps text\n",
    "        pdf.multi_cell(0, 7, text)\n",
    "        # Add extra spacing\n",
    "        pdf.ln(1)\n",
    "\n",
    "    with open(md_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                continue\n",
    "\n",
    "            # Simple Markdown detection logic\n",
    "            if line.startswith(\"# \"):\n",
    "                content = line.replace(\"# \", \"\").strip()\n",
    "                write_line(content, style=\"B\", size=16)\n",
    "            elif line.startswith(\"## \"):\n",
    "                content = line.replace(\"## \", \"\").strip()\n",
    "                write_line(content, style=\"B\", size=14)\n",
    "            elif line.startswith(\"### \"):\n",
    "                content = line.replace(\"### \", \"\").strip()\n",
    "                write_line(content, style=\"B\", size=13)\n",
    "            elif line.startswith(\"- \") or line.startswith(\"* \"):\n",
    "                # Convert to bullet if you want to keep the bullet '•'\n",
    "                # If your markdown uses '*' or '-' for bullets, you can replace them.\n",
    "                bullet_content = line.replace(\"- \", \"• \").replace(\"* \", \"• \").strip()\n",
    "                write_line(bullet_content, size=12)\n",
    "            else:\n",
    "                write_line(line, size=12)\n",
    "\n",
    "    pdf.output(pdf_file)\n",
    "    print(f\"PDF successfully created at: {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_pdf_report_from_markdown(report_path, report_path.split('/')[-1][:-2]+\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate of this code with pydantic prompting\n",
    "# Track token usage and speed - so far min 3-5 and up to 6-10 seconds to generate report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
